{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy8XS6sm8aZK"
      },
      "source": [
        "Adapted From: https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=mjJGEXShp7te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x6bLqhBVqjj"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h37lymrDuX5j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kIq0trEtfwAL"
      },
      "outputs": [],
      "source": [
        "classnames = [\"mistral\", \"rag\", \"3hop-rag\", \"no-label\"]\n",
        "# classnames = [\"mistral\", \"rag\"]\n",
        "\n",
        "num_labels=len(classnames)\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UmMVuhjjgspw"
      },
      "outputs": [],
      "source": [
        "with open(\"labeled_data.pkl\", \"rb\") as f:\n",
        "  labeled_data = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {cls: 0 for cls in classnames}\n",
        "for example in labeled_data:\n",
        "  label = example[\"labels\"]\n",
        "  labels[label] += 1\n"
      ],
      "metadata": {
        "id": "6AYXwTVDq1Az"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBUWBR7frNEr",
        "outputId": "356fe3cf-dd5f-4069-feb2-32c1a35f7bd9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mistral': 380, 'rag': 256, '3hop-rag': 63, 'no-label': 301}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx4sjAVDiUUv"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ze0bxCEYpO4"
      },
      "outputs": [],
      "source": [
        "# Custom Model\n",
        "def encode_astensors(data):\n",
        "  text_lower = data[\"question\"].lower()\n",
        "  label = data[\"labels\"]\n",
        "  encoded_text = tokenizer(text_lower,\n",
        "                            padding='max_length',\n",
        "                            truncation=True,\n",
        "                            max_length=256,\n",
        "                            return_tensors=\"pt\"\n",
        "                            )\n",
        "  # set unlabeled to most difficult level\n",
        "  if label not in classnames:\n",
        "    label = classnames[-1]\n",
        "\n",
        "  encoded_text['labels'] = torch.LongTensor([classnames.index(label)])\n",
        "  return encoded_text\n",
        "\n",
        "# Use this for HF trainer\n",
        "def encode_aslist(data):\n",
        "  text_lower = data[\"question\"].lower()\n",
        "  label = data[\"labels\"]\n",
        "  encoded_text = tokenizer(text_lower,\n",
        "                            padding='max_length',\n",
        "                            truncation=True,\n",
        "                            max_length=128,\n",
        "                            # return_tensors=\"pt\"\n",
        "                            )\n",
        "  if label not in classnames:\n",
        "    label = classnames[-1]\n",
        "\n",
        "  encoded_text['labels'] = [classnames.index(label)]\n",
        "  return encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP9640fji1-6"
      },
      "outputs": [],
      "source": [
        "# encoded_data = list(map(encode_aslist, labeled_data))\n",
        "encoded_data = list(map(encode_astensors, labeled_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVJc60_bm_f1"
      },
      "outputs": [],
      "source": [
        "torch.random.manual_seed(42)\n",
        "train_set, val_set = torch.utils.data.random_split(list(encoded_data), [0.85, 0.15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pDnO8-pi6gv",
        "outputId": "f7eda19e-672e-4fee-8387-c3b704b151f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n"
          ]
        }
      ],
      "source": [
        "print(len(encoded_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edbZsC5yjefW"
      },
      "source": [
        "# Using BERTForSequenceClassification + HF Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivJxP1lXMtcW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_accuracy(output):\n",
        "  pred = np.argmax(output.predictions, axis=1)\n",
        "  labels = output.label_ids\n",
        "  accuracy = (pred[:, np.newaxis] == labels).sum() / pred.shape[0]\n",
        "  return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8jkPje19zfM",
        "outputId": "576282aa-62f5-4850-d77a-138c18a261b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                           problem_type=\"single_label_classification\",\n",
        "                                                           num_labels=num_labels,\n",
        "                                                           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF2ElLXPjkPy"
      },
      "outputs": [],
      "source": [
        "for param in model.base_model.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMafmBpIjnoj"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2faQkIsGaro"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"bert-hotpotqa-classifier-frozen\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    # push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDUt6U62Gk31"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=get_accuracy\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "cXMntJd8GwVu",
        "outputId": "88ba0bbf-b92e-4f4b-e539-4d7b661db9d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 00:49, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.133072</td>\n",
              "      <td>0.440000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.109798</td>\n",
              "      <td>0.453333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.098037</td>\n",
              "      <td>0.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.093290</td>\n",
              "      <td>0.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.092224</td>\n",
              "      <td>0.460000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=270, training_loss=1.1308730513961227, metrics={'train_runtime': 49.5774, 'train_samples_per_second': 85.725, 'train_steps_per_second': 5.446, 'total_flos': 279558006336000.0, 'train_loss': 1.1308730513961227, 'epoch': 5.0})"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1479r70mrpL"
      },
      "source": [
        "# Custom Model (performed worse than default BERT Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtAC4Az4mt_P"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_set, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_set, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4br6ea85mwqB"
      },
      "outputs": [],
      "source": [
        "class BertQuestionClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_dim=768, device=None):\n",
        "    super(BertQuestionClassifier, self).__init__()\n",
        "\n",
        "    if device is None:\n",
        "      self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "    else:\n",
        "      self.device = device\n",
        "\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased').to(self.device)\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Linear(hidden_dim, hidden_dim),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.1),\n",
        "      nn.Linear(hidden_dim, num_labels),\n",
        "    ).to(self.device)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask=None, labels=None,\n",
        "              token_type_ids=None):\n",
        "    outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    sequence_output = outputs[1]\n",
        "    logits = self.classifier(sequence_output)\n",
        "    return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt6kwBNimyoT"
      },
      "outputs": [],
      "source": [
        "model = BertQuestionClassifier()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SytZacWm04f"
      },
      "outputs": [],
      "source": [
        "for param in model.bert.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6c3Ry8Lm25B"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_single_epoch():\n",
        "  n_examples = len(train_set)\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  total_accuracy = 0\n",
        "  for i ,batch in tqdm(enumerate(train_dataloader)):\n",
        "    #print([v[0] for k,v in batch.items()])\n",
        "    batch = {k: v.to(model.device).squeeze(1) for k,v in batch.items()}\n",
        "    logits = model(**batch)\n",
        "    loss = criterion(logits, batch[\"labels\"])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    total_loss += loss.sum().item()\n",
        "    total_accuracy += (logits.argmax(dim=1) == batch[\"labels\"]).sum().item()\n",
        "  return total_loss / n_examples, total_accuracy / n_examples\n",
        "\n",
        "\n",
        "def eval_loop():\n",
        "  n_examples = len(val_set)\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  total_accuracy = 0\n",
        "  for i ,batch in tqdm(enumerate(val_dataloader)):\n",
        "    batch = {k: v.to(model.device).squeeze(1) for k,v in batch.items()}\n",
        "    logits = model(**batch)\n",
        "    loss = criterion(logits, batch[\"labels\"])\n",
        "    total_loss += loss.sum().item()\n",
        "    total_accuracy += (logits.argmax(dim=1) == batch[\"labels\"]).sum().item()\n",
        "  return total_loss / n_examples, total_accuracy / n_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g9gNsUGm55d",
        "outputId": "21c8034b-2745-4d68-e7c9-18ba4ce457b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [00:34,  1.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 train (loss, acc) (0.04211344010689679, 0.6058823529411764)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [00:02,  4.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 val (loss, acc) (0.045101087093353275, 0.5866666666666667)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [00:34,  1.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 train (loss, acc) (0.03533679548431845, 0.7282352941176471)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [00:02,  4.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 val (loss, acc) (0.042889880339304604, 0.6666666666666666)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [00:34,  1.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 train (loss, acc) (0.029017725166152506, 0.8094117647058824)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [00:02,  4.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 val (loss, acc) (0.04265058239301046, 0.7133333333333334)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [00:34,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 train (loss, acc) (0.025109538339516697, 0.84)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [00:02,  4.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 val (loss, acc) (0.050702066818873084, 0.6733333333333333)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "54it [00:34,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 train (loss, acc) (0.017865023972357022, 0.8929411764705882)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [00:02,  4.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 val (loss, acc) (0.05723710079987844, 0.6866666666666666)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0.0\n",
        "for epoch in range(5):\n",
        "  print(epoch, \"train (loss, acc)\", train_single_epoch())\n",
        "  print(epoch, \"val (loss, acc)\", eval_loop())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "edbZsC5yjefW",
        "_1479r70mrpL"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}